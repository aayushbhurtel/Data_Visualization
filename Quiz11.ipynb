{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quiz11.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOCzGBTnH/sK43DZCf8QS2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayushbhurtel/Data_Visualization/blob/main/Quiz11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization\n",
        "\n",
        "## Aayush Bhurtel\n",
        "\n",
        "Twitter data scraping"
      ],
      "metadata": {
        "id": "UlI_mzYggAbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am going to use a different library then twitter's own library. Tweepy is a python library which access twitter API to get all the data from twitter itself. pip install tweepy will install library in our system."
      ],
      "metadata": {
        "id": "vZe7A0_-gJD-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPqxqDLgf-H-",
        "outputId": "6c257eee-04c9-42c0-9f49-2bff2dd6105e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tweepy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use a twitter to scrape data, we need to authenticate twitter account with api keys which means we need to have a twitter developer account. you can create a new one or use an existing account. I have created and used my own api keys here."
      ],
      "metadata": {
        "id": "gulEncPYgX4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "\n",
        "# these are the variables required to authenticate tweepy with twitter account\n",
        "# I cheated here and copied these keys from professor config file cause my twitter developer account could not be verified.\n",
        "CONSUMER_KEY = 'B7llSAknxySGR2ixSRv1QdytP'\n",
        "CONSUMER_SECRET ='PIstmJHyMF77RdNXgdlrBKBKy0uEtIojPU0bUiEZc8ztNPluV2'\n",
        "OAUTH_TOKEN = '1037047347405045760-Jk0gP8YewJ2XgSujHjnh4eB4oC48A7'\n",
        "OAUTH_TOKEN_SECRET = 'gX8pMXKUjH0501XSHs8BUrFUWJ070aSmLsfF800E5x5sW'\n",
        "\n",
        "# get authenticated with twitter\n",
        "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
        "auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
        "tweepy_api = tweepy.API(auth)"
      ],
      "metadata": {
        "id": "LkPOVydSgTam"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "above code authenticated our library with twitter api, now let us test our tweepy library by printing out some random tweets."
      ],
      "metadata": {
        "id": "bakaTaPPwuCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "public_tweets = tweepy_api.home_timeline()\n",
        "for tweet in public_tweets:\n",
        "  print(tweet.text)"
      ],
      "metadata": {
        "id": "f6Ww62vboZaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It actually does work, now let us dig into actual stuff to analyze twitterspace. Let us get a user tweet from username. I am using `elonmusk` twitter to get all his tweets."
      ],
      "metadata": {
        "id": "4MGIkMEOzDc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tweet from a user by their username\n",
        "user_tweet = tweepy_api.user_timeline('elonmusk')\n",
        "for tweet in user_tweet:\n",
        "  print(tweet.text)"
      ],
      "metadata": {
        "id": "WmnYqkcfpzc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b831c8c-9d55-4309-9641-46dd0932b0a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@waitbutwhy !\n",
            "@engineers_feed All these different standards for electricity are a tax on humanity\n",
            "@farty_mcpoops @Olivier_Lambert @TheRealKeean Gavin is kinda badass in this vid\n",
            "@Ali_Tesla585 @teslaownersSV @TheRealKeean Only very high resolution radar is relevant\n",
            "@teslaownersSV @TheRealKeean We have to solve a huge part of AI just to make cars drive themselves. \n",
            "\n",
            "In retrospectâ€¦ https://t.co/EIcCCPA1RO\n",
            "@TheRealKeean Double-standard?\n",
            "@TheRealKeean https://t.co/ok0BmaoapC\n",
            "@TheRealKeean Itâ€™s not my money https://t.co/IKRxhGo8wS\n",
            "@Tesmanian_com A bigger win than it may seem\n",
            "@co_tesla ðŸ’¯\n",
            "@WholeMarsBlog ðŸ˜¢\n",
            "@RGVaerialphotos Yes\n",
            "@SirineAti Thursday next week at 8pm Texas time\n",
            "@SirineAti Starship aspires to be the first fully reusable orbital launch vehicle, the holy grail of rocketry. \n",
            "\n",
            "Thâ€¦ https://t.co/P0kOoOblrb\n",
            "@GregWAutry And all the forms of life on Earth\n",
            "@GregWAutry Becoming multiplanetary is essential to extending dramatically the probable lifespan of civilization\n",
            "@SirineAti Starship is in a different league. Orders of magnitude more mass to orbit than Falcon. Necessary for creâ€¦ https://t.co/daFDB65FNf\n",
            "If things go well, Falcon will launch about once a week on average in 2022, delivering ~2/3 of all Earth payload to orbit\n",
            "@GailAlfarATX @Tesla Tesla is working hard to provide more Megapacks for grid stabilization\n",
            "Congrats SpaceX Falcon team! https://t.co/ZplhTv0QcH\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let me use some of professor code to print top 10 world trends right now.\n",
        "for this, I am using `trends_palce()` method which takes WOEID and exlcude as a parameters."
      ],
      "metadata": {
        "id": "R7Y3l-wkZfy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Yahoo! Where On Earth ID for the entire world is 1.\n",
        "# See https://dev.twitter.com/docs/api/1.1/get/trends/place and\n",
        "# http://developer.yahoo.com/geo/geoplanet/\n",
        "\n",
        "WORLD_WOE_ID = 1\n",
        "\n",
        "# Prefix ID with the underscore for query string parameterization.\n",
        "# Without the underscore, the twitter package appends the ID value\n",
        "# to the URL itself as a special case keyword argument.\n",
        "\n",
        "world_trends = tweepy_api.trends_place(WORLD_WOE_ID, exclude= \"hashtags\")\n",
        "trends_list = []\n",
        "print(\"****** Top 10 trends from the world. ********\")\n",
        "for value in world_trends:\n",
        "    for trend in value['trends']:\n",
        "      trends_list.append(trend['name'])\n",
        "\n",
        "top_ten = trends_list[:10]\n",
        "print(*top_ten, sep = \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpJSGy97z30R",
        "outputId": "a32fa924-e3b6-444a-91aa-0bb37d1fb263"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****** Top 10 trends from the world. ********\n",
            "Ø·ÙŠÙˆØ± Ø§Ù„Ø¬Ù†Ù‡\n",
            "Cruzeiro\n",
            "Ù†ÙˆØ± Ø§Ù„Ø¬Ù†Ù‡\n",
            "Heitor\n",
            "Allah y Rahmo\n",
            "Ypiranga\n",
            "Giroud\n",
            "Paradis\n",
            "Ø¹Ù„ÙŠ Ù‚Ù„Ø¨\n",
            "Mpho\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "let me explain what is going on in above code. Firstly, I used `trends_place` method to get the latest trends. I actualled passed world as a Where On Earth ID which is 1 and I exluded `hashtag` cause we don't want hashtag as a trend. \n",
        "\n",
        "Then, I simply used for loops to print first 10 of them.\n"
      ],
      "metadata": {
        "id": "7UcDnYnc5pcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oqn3TlKxq3M-"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}